---
phase: 06-complete-normering-data
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - apps/web/src/data/tests.ts
  - apps/web/src/data/normering/hosten-2019.json
  - apps/web/src/data/normering/varen-2019.json
  - apps/web/src/data/normering/hosten-2018.json
  - apps/web/src/data/normering/varen-2018.json
  - apps/web/src/data/normering/hosten-2017.json
  - apps/web/src/data/normering/varen-2017.json
  - apps/web/src/data/normering/hosten-2016.json
  - apps/web/src/data/normering/varen-2016.json
  - apps/web/src/data/normering/hosten-2015.json
  - apps/web/src/data/normering/varen-2015.json
  - apps/web/src/data/normering/hosten-2014.json
  - apps/web/src/data/normering/varen-2014.json
  - apps/web/src/data/normering/hosten-2013.json
  - apps/web/public/pdfs/hosten-2019/
  - apps/web/public/pdfs/varen-2019/
  - apps/web/public/pdfs/hosten-2018/
  - apps/web/public/pdfs/varen-2018/
  - apps/web/public/pdfs/hosten-2017/
  - apps/web/public/pdfs/varen-2017/
  - apps/web/public/pdfs/hosten-2016/
  - apps/web/public/pdfs/varen-2016/
  - apps/web/public/pdfs/hosten-2015/
  - apps/web/public/pdfs/varen-2015/
  - apps/web/public/pdfs/hosten-2014/
  - apps/web/public/pdfs/varen-2014/
  - apps/web/public/pdfs/hosten-2013/
autonomous: true

must_haves:
  truths:
    - "All 2013-2019 test pages display normering charts"
    - "Normering PDFs for 13 tests are stored locally"
    - "tests.ts has normering file references for all 13 tests"
    - "All 26 tests in codebase (excluding cancelled VT 2020) have normering data"
  artifacts:
    - path: "apps/web/src/data/normering/hosten-2013.json"
      provides: "HT 2013 normering distribution data"
      contains: "testId.*hosten-2013"
    - path: "apps/web/src/data/normering/hosten-2019.json"
      provides: "HT 2019 normering distribution data"
      contains: "testId.*hosten-2019"
  key_links:
    - from: "apps/web/src/data/tests.ts"
      to: "local PDFs"
      via: "normering file entries"
      pattern: 'fileType.*normering'
---

<objective>
Download normering PDFs and extract JSON data for the 2013-2019 tests (13 tests), completing the full historical archive.

Purpose: Complete normering data for all historical tests, enabling users to see score distributions for every Hogskoleprovet since 2013.
Output: 13 new JSON files with normering data, normering PDFs stored locally, tests.ts updated, full coverage achieved.
</objective>

<execution_context>
@/Users/williamlarsten/.claude/get-shit-done/workflows/execute-plan.md
@/Users/williamlarsten/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/06-complete-normering-data/06-RESEARCH.md
@apps/web/src/data/tests.ts
@apps/web/src/data/normering/hosten-2025.json
@apps/web/src/lib/normering/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Download normering PDFs for 2013-2019 tests</name>
  <files>
    apps/web/public/pdfs/hosten-2019/
    apps/web/public/pdfs/varen-2019/
    apps/web/public/pdfs/hosten-2018/
    apps/web/public/pdfs/varen-2018/
    apps/web/public/pdfs/hosten-2017/
    apps/web/public/pdfs/varen-2017/
    apps/web/public/pdfs/hosten-2016/
    apps/web/public/pdfs/varen-2016/
    apps/web/public/pdfs/hosten-2015/
    apps/web/public/pdfs/varen-2015/
    apps/web/public/pdfs/hosten-2014/
    apps/web/public/pdfs/varen-2014/
    apps/web/public/pdfs/hosten-2013/
    apps/web/src/data/tests.ts
  </files>
  <action>
Download normering PDFs from studera.nu for 13 tests.

**2019 Tests:**
- HT 2019: https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-hosten-2019/
  Store in: apps/web/public/pdfs/hosten-2019/
  Files: norm19b-helaprovet.pdf, norm19b-verb.pdf, norm19b-kvant.pdf

- VT 2019: https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-varen-2019/
  Store in: apps/web/public/pdfs/varen-2019/
  Files: norm19a-helaprovet.pdf, norm19a-verb.pdf, norm19a-kvant.pdf

**2018 Tests:**
- HT 2018: https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-hosten-2018/
  Store in: apps/web/public/pdfs/hosten-2018/
  Files: norm18b-helaprovet.pdf, norm18b-verb.pdf, norm18b-kvant.pdf

- VT 2018: https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-varen-2018/
  Store in: apps/web/public/pdfs/varen-2018/
  Files: norm18a-helaprovet.pdf, norm18a-verb.pdf, norm18a-kvant.pdf

**2017 Tests:**
- HT 2017: https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-hosten-2017/
  Store in: apps/web/public/pdfs/hosten-2017/
  Files: norm17b-helaprovet.pdf, norm17b-verb.pdf, norm17b-kvant.pdf

- VT 2017: https://www.studera.nu/hogskoleprov/fpn/normeringstabellervt2017/
  Store in: apps/web/public/pdfs/varen-2017/
  Files: norm17a-helaprovet.pdf, norm17a-verb.pdf, norm17a-kvant.pdf

**2016 Tests:**
- HT 2016: https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-hosten-20162/
  Store in: apps/web/public/pdfs/hosten-2016/
  Files: norm16b-helaprovet.pdf, norm16b-verb.pdf, norm16b-kvant.pdf

- VT 2016: https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-varen-2016/
  Store in: apps/web/public/pdfs/varen-2016/
  Files: norm16a-helaprovet.pdf, norm16a-verb.pdf, norm16a-kvant.pdf

**2015 Tests:**
- HT 2015: https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-hosten-2015/
  Store in: apps/web/public/pdfs/hosten-2015/
  Files: norm15b-helaprovet.pdf, norm15b-verb.pdf, norm15b-kvant.pdf

- VT 2015: https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-varen-2015/
  Store in: apps/web/public/pdfs/varen-2015/
  Files: norm15a-helaprovet.pdf, norm15a-verb.pdf, norm15a-kvant.pdf

**2014 Tests:**
- HT 2014: https://www.studera.nu/hogskoleprov/fpn/normeringstabell-hosten-2014/
  Store in: apps/web/public/pdfs/hosten-2014/
  Files: norm14b-helaprovet.pdf, norm14b-verb.pdf, norm14b-kvant.pdf

- VT 2014: https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-varen-2014/
  Store in: apps/web/public/pdfs/varen-2014/
  Files: norm14a-helaprovet.pdf, norm14a-verb.pdf, norm14a-kvant.pdf

**2013 Test:**
- HT 2013: https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-hosten-2013/
  Store in: apps/web/public/pdfs/hosten-2013/
  Files: norm13b-helaprovet.pdf, norm13b-verb.pdf, norm13b-kvant.pdf

Note: VT 2013 is not in the codebase tests.ts, so no normering needed for it.

After downloading, update apps/web/src/data/tests.ts with normering file entries for each test.
  </action>
  <verify>
# Verify URLs are accessible before downloading
urls=(
  "https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-hosten-2019/"
  "https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-varen-2019/"
  "https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-hosten-2018/"
  "https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-varen-2018/"
  "https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-hosten-2017/"
  "https://www.studera.nu/hogskoleprov/fpn/normeringstabellervt2017/"
  "https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-hosten-20162/"
  "https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-varen-2016/"
  "https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-hosten-2015/"
  "https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-varen-2015/"
  "https://www.studera.nu/hogskoleprov/fpn/normeringstabell-hosten-2014/"
  "https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-varen-2014/"
  "https://www.studera.nu/hogskoleprov/fpn/normeringstabeller-hosten-2013/"
)
for url in "${urls[@]}"; do
  curl -sI "$url" | head -1 | grep -q "200\|301\|302" && echo "OK: $url" || echo "FAIL: $url"
done

# Verify PDF files exist and have reasonable sizes (>50KB = 51200 bytes)
dirs=(hosten-2019 varen-2019 hosten-2018 varen-2018 hosten-2017 varen-2017 hosten-2016 varen-2016 hosten-2015 varen-2015 hosten-2014 varen-2014 hosten-2013)
for dir in "${dirs[@]}"; do
  for pdf in apps/web/public/pdfs/$dir/norm*.pdf; do
    if [ -f "$pdf" ]; then
      size=$(stat -f%z "$pdf" 2>/dev/null || stat -c%s "$pdf" 2>/dev/null)
      if [ "$size" -gt 51200 ]; then
        echo "OK: $pdf ($size bytes)"
      else
        echo "FAIL: $pdf too small ($size bytes)"
      fi
    else
      echo "FAIL: $pdf not found"
    fi
  done
done

# Count all normering PDFs (should be 78 total for full coverage)
find apps/web/public/pdfs -name "norm*.pdf" | wc -l
# Expected: 78 files (3 for hosten-2025 + 9 from plan-01 + 27 from plan-02 + 39 new)

# Check tests.ts has normering entries for all tests
grep -c "normering" apps/web/src/data/tests.ts
# Should show 78 (3*26 = 78 total normering files)
  </verify>
  <done>
39 normering PDFs downloaded for 2013-2019 tests with verified file sizes (all >50KB). tests.ts updated with normering file entries for all 13 tests.
  </done>
</task>

<task type="auto">
  <name>Task 2: Extract, validate, and finalize normering data for 2013-2019 tests</name>
  <files>
    apps/web/src/data/normering/hosten-2019.json
    apps/web/src/data/normering/varen-2019.json
    apps/web/src/data/normering/hosten-2018.json
    apps/web/src/data/normering/varen-2018.json
    apps/web/src/data/normering/hosten-2017.json
    apps/web/src/data/normering/varen-2017.json
    apps/web/src/data/normering/hosten-2016.json
    apps/web/src/data/normering/varen-2016.json
    apps/web/src/data/normering/hosten-2015.json
    apps/web/src/data/normering/varen-2015.json
    apps/web/src/data/normering/hosten-2014.json
    apps/web/src/data/normering/varen-2014.json
    apps/web/src/data/normering/hosten-2013.json
  </files>
  <action>
Extract normering data from PDFs into JSON format for all 13 tests.

For each test:

1. Read helaprovet PDF - extract 41-row distribution (0.00 to 2.00 in 0.05 steps)
2. Read verbal PDF - extract 21-row distribution (0.0 to 2.0 in 0.1 steps)
3. Read kvantitativ PDF - extract 21-row distribution (0.0 to 2.0 in 0.1 steps)
4. Create JSON file matching hosten-2025.json schema

**Test dates for JSON testDate field:**
- hosten-2019: 2019-10-20
- varen-2019: 2019-04-06
- hosten-2018: 2018-10-21
- varen-2018: 2018-03-31
- hosten-2017: 2017-10-28
- varen-2017: 2017-04-01
- hosten-2016: 2016-10-29
- varen-2016: 2016-04-02
- hosten-2015: 2015-10-24
- varen-2015: 2015-03-28
- hosten-2014: 2014-10-25
- varen-2014: 2014-03-29
- hosten-2013: 2013-10-26

**Validation for each file:**
- Total: 41 rows, cumulative ends at 100%
- Verbal/Kvant: 21 rows each, cumulative ends at 100%
- Mean typically 0.5-1.5, stdDev typically 0.2-0.6

**Older PDF notes:**
- Pre-2020 PDFs may have slightly different formatting but same data structure
- Participant counts typically 70,000-85,000 in pre-COVID era (higher than 2020-2022)

**Final verification after all extractions:**
- Run full build to confirm all pages work
- Check a sample of test pages across different years to verify charts render
  </action>
  <verify>
# Count all JSON files (should be 26 for full coverage)
ls apps/web/src/data/normering/*.json | wc -l
# Expected: 26 files (all tests in codebase)

# Validate all JSON syntax
for f in apps/web/src/data/normering/*.json; do
  node -e "JSON.parse(require('fs').readFileSync('$f', 'utf8'))" && echo "OK: $f"
done

# DATA ACCURACY VALIDATION - Compare extracted JSON against source PDFs
# Sample tests from each era (2013, 2015, 2019) to verify accuracy
sample_slugs=(hosten-2013 hosten-2015 hosten-2019)
for slug in "${sample_slugs[@]}"; do
  echo "=== Checking $slug ==="
  f="apps/web/src/data/normering/$slug.json"
  if [ -f "$f" ]; then
    node -e "
      const data = JSON.parse(require('fs').readFileSync('$f', 'utf8'));
      console.log('testId:', data.testId);
      console.log('total.mean:', data.total.mean);
      console.log('total.stdDev:', data.total.stdDev);
      console.log('total.totalParticipants:', data.total.totalParticipants);
      console.log('total.distribution rows:', data.total.distribution.length, '(expected: 41)');
      console.log('first row:', JSON.stringify(data.total.distribution[0]));
      console.log('last row:', JSON.stringify(data.total.distribution[data.total.distribution.length-1]));
      console.log('verbal rows:', data.verbal.distribution.length, '(expected: 21)');
      console.log('kvant rows:', data.kvantitativ.distribution.length, '(expected: 21)');
    "
    # MANUAL CHECK: Compare these printed values against the source PDF to verify accuracy
  fi
done

# Full verification of all 13 new JSON files
slugs=(hosten-2019 varen-2019 hosten-2018 varen-2018 hosten-2017 varen-2017 hosten-2016 varen-2016 hosten-2015 varen-2015 hosten-2014 varen-2014 hosten-2013)
for slug in "${slugs[@]}"; do
  f="apps/web/src/data/normering/$slug.json"
  if [ -f "$f" ]; then
    node -e "
      const data = JSON.parse(require('fs').readFileSync('$f', 'utf8'));
      const totalOk = data.total.distribution.length === 41;
      const verbalOk = data.verbal.distribution.length === 21;
      const kvantOk = data.kvantitativ.distribution.length === 21;
      if (totalOk && verbalOk && kvantOk) {
        console.log('OK: $slug - all row counts correct');
      } else {
        console.log('FAIL: $slug - row counts: total=' + data.total.distribution.length + ' verbal=' + data.verbal.distribution.length + ' kvant=' + data.kvantitativ.distribution.length);
      }
    "
  else
    echo "FAIL: $slug - file not found"
  fi
done

# RUNTIME VERIFICATION - Verify getNormeringData() can load files from each era
cd apps/web && node -e "
  const fs = require('fs');
  // Test representative slugs from each era
  const slugs = ['hosten-2013', 'hosten-2015', 'hosten-2019'];
  for (const slug of slugs) {
    const path = 'src/data/normering/' + slug + '.json';
    if (fs.existsSync(path)) {
      const data = JSON.parse(fs.readFileSync(path, 'utf8'));
      if (data && data.testId === slug && data.total && data.total.distribution) {
        console.log('OK: ' + slug + ' - data loads correctly');
      } else {
        console.log('FAIL: ' + slug + ' - invalid structure');
      }
    } else {
      console.log('FAIL: ' + slug + ' - file not found');
    }
  }
"

# Full build
cd apps/web && bun run build
# Should succeed without errors

# List all JSON files to confirm full coverage
ls -la apps/web/src/data/normering/
  </verify>
  <done>
13 new JSON files created for 2013-2019 tests. Full normering coverage achieved: 26 JSON files for all 26 tests in codebase. Data accuracy verified against source PDFs (mean, stdDev, first/last rows for sample tests). Runtime verification confirms getNormeringData() loads data from each era correctly. Build passes. All test pages display normering charts.
  </done>
</task>

</tasks>

<verification>
1. 39 normering PDFs downloaded to correct directories with verified sizes
2. tests.ts has normering entries for all 26 tests
3. 26 JSON files exist (full coverage)
4. All JSON files validated for structure
5. Data accuracy verified against source PDFs (sample tests from 2013, 2015, 2019)
6. Runtime verification: getNormeringData() loads data from each era correctly
7. Build succeeds
8. Sample test pages from each era display normering charts correctly
</verification>

<success_criteria>
- 39 normering PDFs downloaded and stored locally with verified sizes
- tests.ts updated with normering file references for all 13 tests (2013-2019)
- 13 new JSON files created with valid normering data
- Total coverage: 26/26 tests have normering JSON data
- Data accuracy verified: mean, stdDev, totalParticipants, first/last distribution rows match source PDFs
- Runtime verification: getNormeringData() loads data from all eras correctly
- bun run build succeeds without errors
- Phase 6 goal achieved: All historical tests with normeringstabeller have their data displayed
</success_criteria>

<output>
After completion, create `.planning/phases/06-complete-normering-data/06-03-SUMMARY.md`
</output>
